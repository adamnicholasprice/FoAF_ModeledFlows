{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fb12c-474a-4b14-96a9-927a42eb4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import xarray as xr\n",
    "import matplotlib.colors as pltc\n",
    "import geopandas\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import s3fs\n",
    "import sys, os, glob,re\n",
    "import multiprocessing as mp\n",
    "import time as time\n",
    "\n",
    "\n",
    "## Cubic feet to cubic meters conversion factor\n",
    "cfs_2_cms = 0.0283168466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60253fdd-fe29-4ff6-b26e-c3ab8f6679a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnwNP = pd.read_csv(\"../data/pnwNP_Info.csv\")\n",
    "\n",
    "### Pull out sites\n",
    "shp = geopandas.read_file(\"../data/VIC_UW/shapefiles/columbia_seg.shp\")\n",
    "shp = pd.merge(pnwNP,shp,left_on='comid',right_on='POI_ID').fillna(0)\n",
    "seg_ids = np.array(shp['seg_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9f8e76-1032-42d1-b71f-bab1e065737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open modeled datasets and extract data at segment locations.\n",
    "pnwVIC = xr.open_mfdataset('../data/VIC_UW/pnwNP_Gages_VIC.nc')\n",
    "pnwVIC = pnwVIC.where(pnwVIC['reachID'].isin(seg_ids),drop=True)\n",
    "\n",
    "pnwPRMS = xr.open_mfdataset('../data/VIC_UW/pnwNP_Gages_PRMS.nc')\n",
    "pnwPRMS = pnwPRMS.where(pnwPRMS['reachID'].isin(seg_ids),drop=True)\n",
    "\n",
    "\n",
    "## Open NWM from NOAA AWS bucket\n",
    "s3_path = 's3://noaa-nwm-retro-v2-zarr-pds' #nwm 2.0\n",
    "\n",
    "# Connect to S3\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "store = s3fs.S3Map(root=s3_path, s3=s3, check=False)\n",
    "\n",
    "# load the dataset\n",
    "ds = xr.open_zarr(store=store, consolidated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a855f251-3af1-4d20-baed-13bfc80abad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12115700\n",
      "12116500\n",
      "12323770\n",
      "12465000\n",
      "12513000\n",
      "13055340\n",
      "13058000\n",
      "13068500\n",
      "13068501\n",
      "13082500\n",
      "13112000\n",
      "13132500\n",
      "13132520\n",
      "13132535\n",
      "13142500\n",
      "13152500\n",
      "13159800\n",
      "13174500\n",
      "13215000\n",
      "13217500\n",
      "13236500\n",
      "13297350\n",
      "14015000\n",
      "14018500\n",
      "14034470\n",
      "14034500\n",
      "14233500\n",
      "14362250\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(shp)):\n",
    "    print(shp['gage'][i])\n",
    "    fields = ['X_00060_00003', 'Date']\n",
    "\n",
    "    ## Get Vic data\n",
    "    VIC = pnwVIC.where(pnwVIC['reachID']==shp['seg_id'][i],drop=True).to_dataframe()\n",
    "    VIC = VIC.drop(['reachID'],axis=1)\n",
    "    VIC= VIC.droplevel('seg')\n",
    "    VIC['time'] = pd.to_datetime(VIC.index,)\n",
    "    VIC['time'] = VIC['time'].dt.tz_localize(None)\n",
    "    VIC = VIC.reset_index(drop=True)\n",
    "    VIC.columns = [\"streamflow_VIC\",\"time\"]\n",
    "\n",
    "\n",
    "\n",
    "    ## Get PRMS data\n",
    "    PRMS = pnwPRMS.where(pnwPRMS['reachID']==shp['seg_id'][i],drop=True).to_dataframe()\n",
    "    PRMS = PRMS.drop(['reachID'],axis=1)\n",
    "    PRMS= PRMS.droplevel('seg')\n",
    "    PRMS['time'] = pd.to_datetime(PRMS.index,)\n",
    "    PRMS['time'] = PRMS['time'].dt.tz_localize(None)\n",
    "    PRMS = PRMS.reset_index(drop=True)\n",
    "    PRMS.columns = [\"streamflow_PRMS\",\"time\"]\n",
    "\n",
    "\n",
    "    ## Combine\n",
    "    datMain = pd.merge(VIC,PRMS, on='time',how='inner')\n",
    "\n",
    "    ## Get NWM 2.0 data\n",
    "    # slice all data using a specific reach identifier and time range\n",
    "    timerange = slice('1979-01-31', '2011-12-31')\n",
    "    dat = ds.sel(feature_id=shp['comid'][i],\n",
    "                 time=timerange).streamflow.persist() \n",
    "\n",
    "    # This step takes a bit longer because it's actually returning the data\n",
    "    dat = dat.resample(time='1d').mean()\n",
    "\n",
    "    NWM = pd.DataFrame(dat.to_pandas())\n",
    "    NWM['time'] = pd.to_datetime(NWM.index)\n",
    "    NWM.columns = [\"streamflow_NWM2d0\",\"time\"]\n",
    "    NWM = NWM.reset_index(drop=True)\n",
    "    NWM[\"gage\"] = shp['gage'][i]\n",
    "\n",
    "\n",
    "    ## Combine with above datasets\n",
    "    datMain = pd.merge(datMain,NWM, on='time',how='inner')\n",
    "\n",
    "    # ## Get NWIS Data\n",
    "    path  = \"../data/NWIS_streamflow/\"\n",
    "    gage = '*'+str(shp['gage'][i])+'*'\n",
    "    file = glob.glob(\"../data/NWIS_streamflow/\"+gage)[0]\n",
    "\n",
    "    NWIS = pd.read_csv(file,usecols=fields)\n",
    "    NWIS.columns = [\"time\",\"streamflow_NWIS\"]\n",
    "    NWIS['time'] = pd.to_datetime(NWIS['time']).dt.tz_localize(None)\n",
    "    NWIS[\"streamflow_NWIS\"] = NWIS[\"streamflow_NWIS\"]*cfs_2_cms\n",
    "\n",
    "    ## Combine all the data\n",
    "    datMain = pd.merge(datMain,NWIS, on='time',how='inner')\n",
    "\n",
    "    datMain.to_csv('../data/pnwNP_modeledData/'+str(shp['gage'][i])+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c4ae64-433b-4c52-9fe5-a72dae618d66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a4bb6-103d-486a-930f-c0bcc2dbf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractModel():\n",
    "    print(shp['gage'])\n",
    "    fields = ['X_00060_00003', 'Date']\n",
    "\n",
    "    ## Get Vic data\n",
    "    VIC = pnwVIC.where(pnwVIC['reachID']==shp['seg_id'],drop=True).to_dataframe()\n",
    "    VIC = VIC.drop(['reachID'],axis=1)\n",
    "    VIC= VIC.droplevel('seg')\n",
    "    VIC['time'] = pd.to_datetime(VIC.index,)\n",
    "    VIC['time'] = VIC['time'].dt.tz_localize(None)\n",
    "    VIC = VIC.reset_index(drop=True)\n",
    "    VIC.columns = [\"streamflow_VIC\",\"time\"]\n",
    "\n",
    "\n",
    "\n",
    "    ## Get PRMS data\n",
    "    PRMS = pnwPRMS.where(pnwPRMS['reachID']==shp['seg_id'],drop=True).to_dataframe()\n",
    "    PRMS = PRMS.drop(['reachID'],axis=1)\n",
    "    PRMS= PRMS.droplevel('seg')\n",
    "    PRMS['time'] = pd.to_datetime(PRMS.index,)\n",
    "    PRMS['time'] = PRMS['time'].dt.tz_localize(None)\n",
    "    PRMS = PRMS.reset_index(drop=True)\n",
    "    PRMS.columns = [\"streamflow_PRMS\",\"time\"]\n",
    "\n",
    "\n",
    "    ## Combine\n",
    "    datMain = pd.merge(VIC,PRMS, on='time',how='inner')\n",
    "\n",
    "    ## Get NWM 2.0 data\n",
    "    # slice all data using a specific reach identifier and time range\n",
    "    timerange = slice('1979-01-31', '2011-12-31')\n",
    "    dat = ds.sel(feature_id=shp['comid'],\n",
    "                 time=timerange).streamflow.persist() \n",
    "\n",
    "    # This step takes a bit longer because it's actually returning the data\n",
    "    dat = dat.resample(time='1d').mean()\n",
    "\n",
    "    NWM = pd.DataFrame(dat.to_pandas())\n",
    "    NWM['time'] = pd.to_datetime(NWM.index)\n",
    "    NWM.columns = [\"streamflow_NWM2d0\",\"time\"]\n",
    "    NWM = NWM.reset_index(drop=True)\n",
    "    NWM[\"gage\"] = shp['gage']\n",
    "\n",
    "\n",
    "    ## Combine with above datasets\n",
    "    datMain = pd.merge(datMain,NWM, on='time',how='inner')\n",
    "\n",
    "    # ## Get NWIS Data\n",
    "    path  = \"../data/NWIS_streamflow/\"\n",
    "    gage = '*'+str(shp['gage'])+'*'\n",
    "    file = glob.glob(\"../data/NWIS_streamflow/\"+gage)[0]\n",
    "\n",
    "    NWIS = pd.read_csv(file,usecols=fields)\n",
    "    NWIS.columns = [\"time\",\"streamflow_NWIS\"]\n",
    "    NWIS['time'] = pd.to_datetime(NWIS['time']).dt.tz_localize(None)\n",
    "    NWIS[\"streamflow_NWIS\"] = NWIS[\"streamflow_NWIS\"]*cfs_2_cms\n",
    "\n",
    "    ## Combine all the data\n",
    "    datMain = pd.merge(datMain,NWIS, on='time',how='inner')\n",
    "\n",
    "    datMain.to_csv('../data/pnwNP_modeledData/'+str(shp['gage'][i])+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b7be1-a98a-46f5-b175-b1759dd716de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pnwModeledDatamp():\n",
    "    print(shp['gage'])\n",
    "    # Make a timer for the processes\n",
    "    start = time.process_time()\n",
    "    \n",
    "    # Step 1: Init multiprocessing.Pool()\n",
    "    pool = mp.Pool(mp.cpu_count()-1)\n",
    "\n",
    "    # Step 2: `pool.starmap` the `buildVTK()` function\n",
    "    results = pool.starmap(extractModel,iterable=shp)\n",
    "\n",
    "    # Step 3: Don't forget to close\n",
    "    pool.close()\n",
    "    \n",
    "    #Finish timing\n",
    "    end = time.process_time()\n",
    "    print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
