{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b5327d-7192-4ff7-8acc-bcf01484e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib_progress import joblib_progress\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a345f72-693e-4e06-8af9-418a4656376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490ba304b7164391acf15ed7c0eab4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tempFunc(i):\n",
    "    pd.DataFrame([i*4])\\\n",
    "    .to_csv(\"./temp/\"+str(i)+\"csv\")\n",
    "    time.sleep(3)\n",
    "\n",
    "with joblib_progress(\"Status\",total = 50):\n",
    "    Parallel(n_jobs=4)(delayed(tempFunc)(i) for i in range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea69cd50-b780-499e-b0e3-068be101b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import xarray as xr\n",
    "import matplotlib.colors as pltc\n",
    "import geopandas\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import s3fs\n",
    "import sys, os, glob,re\n",
    "import multiprocessing as mp\n",
    "import time as time\n",
    "import fsspec\n",
    "from joblib_progress import joblib_progress\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "## Cubic feet to cubic meters conversion factor\n",
    "cfs_2_cms = 0.0283168466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f47c467-07f9-4de2-b04c-46a53c9b5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnwNP = pd.read_csv(\"../data/pnwNPall_InfowStats.csv\")\n",
    "\n",
    "### Pull out sites\n",
    "shp = geopandas.read_file(\"../data/VIC_UW/shapefiles/columbia_seg.shp\")\n",
    "shp = pnwNP.merge(shp,how = 'left',left_on='comid',right_on='POI_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24b69f73-e117-4638-935a-fc105a73f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open modeled datasets (VIC and PRMS) for just reach ID and runoff\n",
    "pnwVIC = xr.open_mfdataset('../data/VIC_UW/vic_historical_first_route_all.nc')[['reachID','IRFroutedRunoff']]\n",
    "\n",
    "\n",
    "pnwPRMS = xr.open_mfdataset('../data/VIC_UW/prms_historical_first_route_all.nc')[['reachID','IRFroutedRunoff']]\n",
    "\n",
    "## Open NWM2.0\n",
    "## Open NWM from NOAA AWS bucket\n",
    "s3_path = 's3://noaa-nwm-retro-v2-zarr-pds' #nwm 2.0\n",
    "\n",
    "# Connect to S3\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "store = s3fs.S3Map(root=s3_path, s3=s3, check=False)\n",
    "\n",
    "# load the dataset\n",
    "ds = xr.open_zarr(store=store, consolidated=True)\n",
    "\n",
    "\n",
    "## Open NWM2.1\n",
    "fs = fsspec.filesystem('s3', anon=True)\n",
    "_file = fs.glob('noaa-nwm-retrospective-2-1-zarr-pds/chrtout.zarr')\n",
    "\n",
    "dsd1 = xr.open_dataset(fs.get_mapper(_file[0]), engine='zarr', backend_kwargs={'consolidated': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "558b4933-40c4-4624-a2b6-3a8534e4a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(shp)):\n",
    "def getModels(i):\n",
    "    print(shp['gage'][i])\n",
    "    fields = ['X_00060_00003', 'Date']\n",
    "\n",
    "    ## Get Vic data\n",
    "    VIC = pnwVIC.where(pnwVIC['reachID']==shp['seg_id'][i],drop=True).to_dataframe()\n",
    "    VIC = VIC.drop(['reachID'],axis=1)\n",
    "    VIC= VIC.droplevel('seg')\n",
    "    VIC['time'] = pd.to_datetime(VIC.index,)\n",
    "    VIC['time'] = VIC['time'].dt.tz_localize(None)\n",
    "    VIC = VIC.reset_index(drop=True)\n",
    "    VIC.columns = [\"streamflow_VIC\",\"time\"]\n",
    "\n",
    "\n",
    "\n",
    "    ## Get PRMS data\n",
    "    PRMS = pnwPRMS.where(pnwPRMS['reachID']==shp['seg_id'][i],drop=True).to_dataframe()\n",
    "    PRMS = PRMS.drop(['reachID'],axis=1)\n",
    "    PRMS= PRMS.droplevel('seg')\n",
    "    PRMS['time'] = pd.to_datetime(PRMS.index,)\n",
    "    PRMS['time'] = PRMS['time'].dt.tz_localize(None)\n",
    "    PRMS = PRMS.reset_index(drop=True)\n",
    "    PRMS.columns = [\"streamflow_PRMS\",\"time\"]\n",
    "\n",
    "\n",
    "    # ## Combine\n",
    "    datMain = pd.merge(VIC,PRMS, on='time',how='outer')\n",
    "\n",
    "    try:\n",
    "        ## Get NWM 2.0 data\n",
    "        # slice all data using a specific reach identifier\n",
    "        dat = ds.sel(feature_id=shp['comid'][i]).streamflow.persist() \n",
    "\n",
    "        # This step takes a bit longer because it's actually returning the data\n",
    "        dat = dat.resample(time='1d').mean()\n",
    "\n",
    "        NWM = pd.DataFrame(dat.to_pandas())\n",
    "        NWM['time'] = pd.to_datetime(NWM.index)\n",
    "        NWM['time'] = NWM['time'].dt.tz_localize(None)\n",
    "        NWM.columns = [\"streamflow_NWM2d0\",\"time\"]\n",
    "        NWM = NWM.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        datMain = pd.merge(datMain,NWM,on='time',how='outer')\n",
    "\n",
    "\n",
    "        ## Get NWM 2.1 data\n",
    "        # slice all data using a specific reach identifier\n",
    "        df = dsd1.sel(feature_id=shp['comid'][i]).streamflow.persist() \n",
    "\n",
    "        NWM2d1 = pd.DataFrame(df.to_pandas()).resample('1d').mean()\n",
    "        NWM2d1['time'] = pd.to_datetime(NWM2d1.index)\n",
    "        NWM2d1['time'] = NWM2d1['time'].dt.tz_localize(None)\n",
    "        NWM2d1.columns = [\"streamflow_NWM2d1\",\"time\"]\n",
    "        NWM2d1 = NWM2d1.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # Combine with previous modeled data\n",
    "        datMain = pd.merge(datMain,NWM2d1, on='time',how='outer')\n",
    "\n",
    "        # ## Get NWIS Data\n",
    "        path  = \"../data/NWIS_streamflow/\"\n",
    "        gage = '*'+str(shp['gage'][i])+'*'\n",
    "        file = glob.glob(\"../data/NWIS_streamflow/daily/\"+gage)[0]\n",
    "\n",
    "\n",
    "        fields = ['00060_Mean','datetime']\n",
    "        NWIS = pd.read_csv(file,usecols=fields)\n",
    "        NWIS.columns = [\"time\",\"streamflow_NWIS\"]\n",
    "        NWIS['time'] = pd.to_datetime(NWIS['time']).dt.tz_localize(None)\n",
    "        NWIS[\"streamflow_NWIS\"] = NWIS[\"streamflow_NWIS\"]*cfs_2_cms\n",
    "\n",
    "        ## Combine all the data\n",
    "        datMain = pd.merge(datMain,NWIS, on='time',how='outer')\n",
    "        datMain[\"gage\"] = shp['gage'][i]\n",
    "\n",
    "\n",
    "        datMain.sort_values(by='time',ascending=True) \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .to_csv('../data/pnwNP_modeledData/'+str(shp['gage'][i])+\".csv\")\n",
    "\n",
    "    except:\n",
    "        print(\"No NWM data\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe716d16-a0e7-4de7-8803-8272859b395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10366000\n"
     ]
    }
   ],
   "source": [
    "getModels(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59630c6-60f1-4859-9bee-db451cb0a90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
